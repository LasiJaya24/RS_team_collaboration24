{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Planet NDVI time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This script is designed to process 4 band multispectral\n",
    "# satellite images from Planet Labs to calculate the \n",
    "# Normalized Difference Water Index (NDVI).\n",
    "\n",
    "# Classification is being performed as negative NDVI\n",
    "\n",
    "'''\n",
    "Perform classification ##### (<= Negative NDVI, else >= NDVI) #####\n",
    "classified = np.where(ndvi <= ndvi_threshold, 1, nodata).astype(np.uint8)\n",
    "print(f\"Classified Min: {classified.min()}, Max: {classified.max()}\")\n",
    "'''\n",
    "# This Python script is setup to calculate the surface area of water on the \n",
    "# landscape or targeted at individual waterbodies\n",
    "\n",
    "# Planet imagery across Queensland is covered by 3 UTM zones\n",
    "# Ensure your AOI projection matches your imagery\n",
    "\n",
    "# UTM Zone 54S: This zone covers the easternmost part of \n",
    "# Queensland, including the eastern coast and cities such as Cairns.\n",
    "\n",
    "# UTM Zone 55S: Most of central Queensland falls under this zone.\n",
    "\n",
    "# UTM Zone 56S: The vast majority of southeastern Queensland,\n",
    "# including Brisbane and the Gold Coast, is within this zone.\n",
    "\n",
    "# 28/01/2025\n",
    "\n",
    "# Remote Sensing\n",
    "# remotesensing@rdmw.qld.gov.au\n",
    "\n",
    "# Craig Turner\n",
    "# craig.turner@rdmw.qld.gov.au \n",
    " \n",
    "# Department of Local Government, Water, and Volunteers\n",
    "# Water Operations & Systems\n",
    "# Strategic Compliance, Intelligence, & Investigations\n",
    "\n",
    "software_version = 0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add any additional modules to Version information list below\n",
    "\n",
    "# Standard library imports\n",
    "import datetime\n",
    "from datetime import datetime as dt\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Third-party library imports\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')  # Prevent inline display of imagery\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.figure import Figure\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg\n",
    "from PIL import Image, ImageTk\n",
    "import pytz\n",
    "from pyproj import CRS\n",
    "import rasterio\n",
    "from rasterio.io import MemoryFile\n",
    "from rasterio.mask import mask\n",
    "from rasterio.plot import show\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog, messagebox, Label, Tk, ttk\n",
    "import xlsxwriter\n",
    "from xlsxwriter.workbook import Workbook\n",
    "\n",
    "# Version information list\n",
    "modules = {\n",
    "    'datetime': datetime,\n",
    "    'os': os,\n",
    "    'sys': sys,\n",
    "    'glob': glob,\n",
    "    'NumPy': np,\n",
    "    'pandas': pd,\n",
    "    'GeoPandas': gpd,\n",
    "    'Maplotlib': plt,    \n",
    "    'PIL': Image,\n",
    "    'pytz': pytz,\n",
    "    'pyproj': CRS,\n",
    "    'rasterio': rasterio,\n",
    "    'tkinter': tk,\n",
    "    'XlsxWriter': xlsxwriter\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declare functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to calculate the covered area in square metres\n",
    "def calculate_covered_area(udm_band, udm_meta, aoi):\n",
    "    # Transform the pixel coordinates to the geographic coordinates\n",
    "    transform = udm_meta['transform']\n",
    "    \n",
    "    # Count the number of pixels that are True within the mask (indicating presence of cloud/haze/shadow)\n",
    "    pixel_area = (transform[0] * -transform[4])  # The area of a pixel in square metres\n",
    "    covered_pixels = udm_band.sum()\n",
    "    covered_area_sqm = covered_pixels * pixel_area\n",
    "    \n",
    "    return covered_area_sqm\n",
    "\n",
    "# Function to clip raster to shapefile\n",
    "def clip_raster_to_shapefile(raster_file, shapefile):\n",
    "    # Load the boundaries of the clip shapefile using geopandas\n",
    "    shp = gpd.read_file(shapefile)\n",
    "    \n",
    "    # Open the source raster using rasterio\n",
    "    with rasterio.open(raster_file) as src:\n",
    "        # Clip the raster with the shapefile using a mask\n",
    "        out_image, out_transform = mask(src, shp.geometry, crop=True)\n",
    "        # Copy and update the metadata for the clipped raster\n",
    "        out_meta = src.meta\n",
    "        out_meta.update({\n",
    "            \"height\": out_image.shape[1],\n",
    "            \"width\": out_image.shape[2],\n",
    "            \"transform\": out_transform\n",
    "        })\n",
    "    \n",
    "    # Return the in-memory clipped raster data and the updated metadata\n",
    "    return out_image, out_meta    \n",
    "    \n",
    "# Function to classify raster into two classes based on a threshold\n",
    "def classify_raster(raster_file, threshold, output_file):\n",
    "    with rasterio.open(raster_file) as src:\n",
    "        # Read raster band 1\n",
    "        band1 = src.read(1)\n",
    "\n",
    "        # Apply classification based on threshold\n",
    "        classified = np.where(band1 > threshold, 0, 1).astype(np.uint8)\n",
    "\n",
    "        # Check for existing nodata value in the raster's metadata\n",
    "        nodata = src.nodata\n",
    "        if nodata is None:\n",
    "            nodata = 0  # Default to 0 or another appropriate nodata value for your dataset\n",
    "\n",
    "        # Apply the classification\n",
    "        classified = np.where(band1 > threshold, 1, nodata).astype(np.uint8)\n",
    "\n",
    "        # Update metadata for output\n",
    "        out_meta = src.meta.copy()\n",
    "        out_meta.update({\n",
    "            \"driver\": \"GTiff\",\n",
    "            \"dtype\": \"uint8\",\n",
    "            \"nodata\": nodata,\n",
    "            \"count\": 1,\n",
    "            \"compress\": \"lzw\"\n",
    "        })\n",
    "\n",
    "    # Write out the raster\n",
    "    with rasterio.open(output_file, \"w\", **out_meta) as dest:\n",
    "        dest.write(classified, 1)\n",
    "\n",
    "# Function to calculate area\n",
    "def measure_areas(masked_raster_band, threshold, pixel_area_m2):\n",
    "    # Mask for valid data (non-NaN values)\n",
    "    valid_data_mask = ~np.isnan(masked_raster_band)\n",
    "\n",
    "    # Masks for areas above and below the threshold\n",
    "    above_threshold_mask = (masked_raster_band >= threshold) & valid_data_mask\n",
    "    below_threshold_mask = (masked_raster_band < threshold) & valid_data_mask\n",
    "    \n",
    "    # Calculate areas for above and below threshold\n",
    "    above_threshold_area = np.sum(above_threshold_mask) * pixel_area_m2\n",
    "    below_threshold_area = np.sum(below_threshold_mask) * pixel_area_m2\n",
    "\n",
    "    # Calculate the total valid area\n",
    "    total_valid_area = above_threshold_area + below_threshold_area\n",
    "\n",
    "    # Calculating the percentages\n",
    "    percentage_above_threshold = (above_threshold_area / total_valid_area) * 100 if total_valid_area != 0 else 0\n",
    "    percentage_below_threshold = (below_threshold_area / total_valid_area) * 100 if total_valid_area != 0 else 0\n",
    "\n",
    "    return total_valid_area, below_threshold_area, percentage_below_threshold, above_threshold_area, percentage_above_threshold\n",
    "\n",
    "# Function to retrieve projection human readable name\n",
    "def get_projection_name(epsg_code):\n",
    "    crs = CRS.from_epsg(epsg_code)\n",
    "    return crs.name\n",
    "\n",
    "# Convert UTC time in filename to AEST (UTC+10:00)\n",
    "def filename_utc_to_aest(filename):\n",
    "    # Extract the timestamp from the filename, assume the format is: YYYYMMDD_HHMMSS\n",
    "    file_timestamp_str = filename.split('_')[1]\n",
    "    # Assuming the date is at the beginning of the filename '20231118'\n",
    "    file_date_str = filename.split('_')[0]\n",
    "    file_datetime_str = file_date_str + '_' + file_timestamp_str\n",
    "\n",
    "    # Create a datetime object\n",
    "    file_datetime = dt.strptime(file_datetime_str, \"%Y%m%d_%H%M%S\")\n",
    "\n",
    "    # Timezone conversion from UTC to AEST\n",
    "    local_tz = pytz.timezone('Australia/Brisbane')\n",
    "    local_dt = file_datetime.replace(tzinfo=pytz.utc).astimezone(local_tz)\n",
    "\n",
    "    # Format the datetime object to a string for full AEST timestamp\n",
    "    local_dt_full_str = local_dt.strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "    # Format the datetime object to a string for just the date portion\n",
    "    local_dt_date_str = local_dt.strftime('%d/%m/%Y')\n",
    "\n",
    "    return local_dt_full_str, local_dt_date_str\n",
    "\n",
    "# GUI stuff, more details to be added\n",
    "class PlaceholderEntry(tk.Entry):\n",
    "    def __init__(self, master=None, placeholder=\"PLACEHOLDER\", color='grey', **kwargs):\n",
    "        super().__init__(master=master, **kwargs)\n",
    "        self.placeholder = placeholder\n",
    "        self.placeholder_color = color\n",
    "        self.default_fg_color = self['fg']\n",
    "\n",
    "        self.bind(\"<FocusIn>\", self.foc_in)\n",
    "        self.bind(\"<FocusOut>\", self.foc_out)\n",
    "\n",
    "        self.put_placeholder()\n",
    "\n",
    "    def put_placeholder(self):\n",
    "        self.insert(0, self.placeholder)\n",
    "        self['fg'] = self.placeholder_color\n",
    "\n",
    "    def foc_in(self, *args):\n",
    "        if self.get() == self.placeholder and self['fg'] == self.placeholder_color:\n",
    "            self.delete('0', 'end')\n",
    "            self['fg'] = self.default_fg_color\n",
    "\n",
    "    def foc_out(self, *args):\n",
    "        if not self.get():\n",
    "            self.put_placeholder()\n",
    "\n",
    "def selection_changed(event):\n",
    "    print(\"Selected:\", combobox.get())\n",
    "\n",
    "def select_file(entry_widget):\n",
    "    # Define the file type filter\n",
    "    filetypes = (\n",
    "        ('Shapefiles', '*.shp'),\n",
    "    )\n",
    "\n",
    "    # Open file dialog with .shp filter\n",
    "    file_path = filedialog.askopenfilename(title=\"Select file\", filetypes=filetypes)\n",
    "\n",
    "    # Check if a file was selected\n",
    "    if file_path:\n",
    "        entry_widget.delete(0, tk.END)  # Remove any existing text in the entry\n",
    "        entry_widget.insert(0, file_path)  # Insert the selected path\n",
    "\n",
    "def select_directory(entry_widget):\n",
    "    directory_path = filedialog.askdirectory(title=\"Select directory\")\n",
    "    entry_widget.delete(0, tk.END)\n",
    "    entry_widget.insert(0, directory_path)\n",
    "\n",
    "def submit_form():\n",
    "    global job_id, pfi, analyst, ndvi_threshold, colour_map, base_dir, aoi, gui_path\n",
    "\n",
    "    job_id = field1_entry.get()\n",
    "    pfi = field2_entry.get()\n",
    "    analyst = name_combobox.get()\n",
    "    colour_map = colourmap_combobox.get()\n",
    "    base_dir = source1_entry.get()\n",
    "    aoi = source2_entry.get()\n",
    "    gui_path = output1_entry.get()\n",
    "\n",
    "    # Get the NDVI threshold as string and then convert it to a float after stripping whitespace.\n",
    "    ndvi_threshold_str = field4_entry.get().strip()\n",
    "\n",
    "    try:\n",
    "        # Convert the threshold value to float and check its range.\n",
    "        ndvi_threshold = float(ndvi_threshold_str)\n",
    "        if not -1.0 <= ndvi_threshold <= 1.0:\n",
    "            messagebox.showerror(\"Input Error\", \"Invalid NDVI Threshold value. Please enter a value between -1 and 1.\")\n",
    "            return\n",
    "    except ValueError:\n",
    "        messagebox.showerror(\"Input Error\", \"Invalid NDVI Threshold value. Please enter a numerical value.\")\n",
    "        return\n",
    "    \n",
    "    # After submitting the form and processing the data without any errors, close the GUI.\n",
    "    root.destroy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GUI - Create output folder - Set variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear input variables\n",
    "job_id = None\n",
    "pfi = None\n",
    "analyst = None\n",
    "ndvi_threshold = None\n",
    "colour_map = None \n",
    "base_dir = None\n",
    "aoi = None\n",
    "gui_path = None\n",
    "\n",
    "# Option lists\n",
    "colour_map_options = ['viridis', 'plasma', 'inferno', 'magma', 'cividis', \n",
    "                      'viridis_r', 'plasma_r', 'inferno_r', 'magma_r', 'cividis_r']\n",
    "name_options = ['Jason Dechastel', 'Lasinidu Jayarathna', 'Eva Kovaks', 'Craig Turner']\n",
    "\n",
    "# Create corporate colours\n",
    "Cybernetic = \"#275c6d\"  # Primary\n",
    "Prosperity = \"#077297\"  # Secondary\n",
    "Bold_Blue = \"#023a57\"   # Secondary\n",
    "\n",
    "Mangrove = \"#4b623b\"    # Primary\n",
    "Waterhole = \"#a69b5e\"   # Secondary\n",
    "H20 = \"#315450\"         # Secondary\n",
    "\n",
    "Terrain = \"#8c4d36\"     # Primary\n",
    "Ochre = \"#ac6d29\"       # Secondary\n",
    "Sunrise = \"#c48c33\"     # Secondary\n",
    "\n",
    "# Assign colours\n",
    "main_bg_colour =  Mangrove \n",
    "frame_bg_colour = Waterhole\n",
    "label_bg_colour = Waterhole\n",
    "entry_bg_colour = \"black\" # Black entry widget background\n",
    "button_bg_colour = \"white\"  # White button\n",
    "\n",
    "# Main window creation and setup\n",
    "root = tk.Tk()\n",
    "root.title(\"Planet NDVI time series\")\n",
    "root.configure(bg=main_bg_colour)\n",
    "root.attributes('-topmost', True)\n",
    "               \n",
    "# Load an image using PIL's Image\n",
    "image_path = 'Qld-CoA-Stylised-1L-mono_rev.png'\n",
    "image = Image.open(image_path)\n",
    "photo = ImageTk.PhotoImage(image)\n",
    "\n",
    "# Create a frame to hold the image and the title\n",
    "header_frame = tk.Frame(root, bg = frame_bg_colour)\n",
    "header_frame.grid(row=0, column=0, columnspan=3, sticky=\"nw\", padx=5, pady=5)\n",
    "\n",
    "# Display Queensland Coat of Arms in the top-left corner of the GUI\n",
    "image_label = tk.Label(header_frame, image=photo, bg=frame_bg_colour)\n",
    "image_label.grid(row=0, column=0, sticky=\"nw\")\n",
    "\n",
    "# Display title to the right of the Queensland Coat of Arms\n",
    "title_label = tk.Label(header_frame, text=\"Planet NDVI time series\\n \\nStrategic Compliance, Intelligence, & Investigations \", font=(\"Arial\", 22), fg=\"#ffffff\", bg=label_bg_colour)\n",
    "title_label.grid(row=0, column=1, sticky=\"w\")\n",
    "\n",
    "# Create labels and entry widgets for each field with placeholders\n",
    "tk.Label(root, text=\"Job ID:\").grid(row=1, column=0, sticky=\"e\")\n",
    "field1_entry = PlaceholderEntry(root, placeholder=\"e.g., 231132\", width=28)\n",
    "field1_entry.grid(row=1, column=1, padx=5, pady=5, sticky=\"w\")\n",
    "\n",
    "tk.Label(root, text=\"PFI:\").grid(row=2, column=0, sticky=\"e\")\n",
    "field2_entry = PlaceholderEntry(root, placeholder=\"Persistent Feature Identifier\", width=28)\n",
    "field2_entry.grid(row=2, column=1, padx=5, pady=5, sticky=\"w\")\n",
    "\n",
    "ttk.Label(root, text=\"Name:\").grid(row=3, column=0, sticky=\"e\")\n",
    "name_combobox = ttk.Combobox(root, values=name_options, width=25)\n",
    "name_combobox.grid(row=3, column=1, padx=5, pady=5, sticky=\"w\")\n",
    "name_combobox.set('Craig Turner')  # Set a default value\n",
    "\n",
    "tk.Label(root, text=\"NDVI Threshold:\").grid(row=4, column=0, sticky=\"e\")\n",
    "field4_entry = PlaceholderEntry(root, placeholder=\"0\", width=28)\n",
    "field4_entry.grid(row=4, column=1, padx=5, pady=5, sticky=\"w\")\n",
    "\n",
    "ttk.Label(root, text=\"Matplotlib colourmap:\").grid(row=5, column=0, sticky=\"e\")\n",
    "colourmap_combobox = ttk.Combobox(root, values=colour_map_options, width=25)\n",
    "colourmap_combobox.grid(row=5, column=1, padx=5, pady=5, sticky=\"w\")\n",
    "colourmap_combobox.set('viridis')  # Set a default value\n",
    "\n",
    "tk.Label(root, text=\"Imagery:\").grid(row=6, column=0, sticky=\"e\")\n",
    "source1_entry = PlaceholderEntry(root, placeholder=\"C:/Local Imagery/241809-241810-241689/TOA\", width=40)\n",
    "source1_entry.grid(row=6, column=1, padx=5, pady=5, sticky=\"we\")\n",
    "tk.Button(root, text=\"Browse\", command=lambda: select_directory(source1_entry)).grid(row=6, column=2, padx=5, pady=5, sticky=\"w\")\n",
    "\n",
    "tk.Label(root, text=\"Shapefile:\").grid(row=7, column=0, sticky=\"e\")\n",
    "source2_entry = PlaceholderEntry(root, placeholder=\"C:/Local Shapefiles/241779 Ballangarry AOI/SCP_ExportFeatures.shp\", width=40)\n",
    "source2_entry.grid(row=7, column=1, padx=5, pady=5, sticky=\"we\")\n",
    "tk.Button(root, text=\"Browse\", command=lambda: select_file(source2_entry)).grid(row=7, column=2, padx=5, pady=5, sticky=\"w\")\n",
    "\n",
    "tk.Label(root, text=\"Output:\").grid(row=8, column=0, sticky=\"e\")\n",
    "output1_entry = PlaceholderEntry(root, placeholder=\"c:\\Local Output\", width=40)\n",
    "output1_entry.grid(row=8, column=1, padx=5, pady=5, sticky=\"we\")\n",
    "tk.Button(root, text=\"Browse\", command=lambda: select_directory(output1_entry)).grid(row=8, column=2, padx=5, pady=5, sticky=\"w\")\n",
    "\n",
    "# Submit button creation\n",
    "submit_button = tk.Button(root, text=\"Submit\", command=submit_form)\n",
    "submit_button.grid(row=9, column=0, columnspan=3, pady=10)\n",
    "\n",
    "# Display Remote Sensing email address in GUI\n",
    "title_label = tk.Label(root, text=\"remotesensing@rdmw.qld.gov.au\", font=(\"Arial\", 10), fg=\"#ffffff\", bg=main_bg_colour)\n",
    "title_label.grid(row=10, column=0, sticky=\"w\")\n",
    "\n",
    "# Display software version in GUI\n",
    "title_label = tk.Label(root, text=f\"Version {software_version}\", font=(\"Arial\", 10), fg=\"#ffffff\", bg=main_bg_colour)\n",
    "title_label.grid(row=10, column=2, sticky=\"se\")\n",
    "\n",
    "# Start the GUI event loop\n",
    "root.mainloop()\n",
    "\n",
    "# Only read analytical imagery\n",
    "image_files = glob.glob(os.path.join(base_dir, \"*Analytic*.tif\"))\n",
    "\n",
    "# Get current date and time\n",
    "current_datetime = datetime.datetime.now()\n",
    "\n",
    "# Format date and time into a string\n",
    "formatted_datetime = current_datetime.strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "# Define the name of the output subfolder\n",
    "subfolder_name = f\"{formatted_datetime}_Job_ID_{job_id}_Threshold_{ndvi_threshold}_Planet NDVI time series\"\n",
    "\n",
    "# Create the full path for the new subfolder\n",
    "output_path = os.path.join(gui_path, subfolder_name)\n",
    "\n",
    "# Create the subfolder\n",
    "os.makedirs(output_path)\n",
    "\n",
    "# Output Excel\n",
    "excel_filename = f\"{formatted_datetime}_Job_ID_{job_id}_Threshold_{ndvi_threshold}_Planet_NDVI_time_series.xlsx\"\n",
    "excel_file_path = os.path.join(output_path, excel_filename)\n",
    "\n",
    "# Specify the buffer distance (in units of the raster's CRS)\n",
    "buffer_distance = 50  # Adjust this value as needed\n",
    "\n",
    "# Collect Python version information\n",
    "python_version = sys.version\n",
    "python_environment = sys.executable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open shapefile using geopandas\n",
    "shp = gpd.read_file(aoi)\n",
    "\n",
    "# Read the first tiff file:    \n",
    "raster_image = rasterio.open(image_files[1])\n",
    "tiff_band_1 = raster_image.read(1)\n",
    "\n",
    "# Print shape and raster CRS info:\n",
    "# print ('Check to ensure shapefile and raster projections match\\n')\n",
    "\n",
    "# Check and get the projection name if shp.crs has an EPSG code\n",
    "shp_epsg_code = shp.crs.to_epsg()\n",
    "if shp_epsg_code:\n",
    "    shp_projection_name = get_projection_name(shp_epsg_code)\n",
    "    print(f\"The projection name for the shapefile with EPSG code {shp_epsg_code} is, {shp_projection_name}.\\n\")\n",
    "else:\n",
    "    print('The shapefile CRS does not have an EPSG code.')\n",
    "\n",
    "# Check and get the projection name if raster_image.crs has an EPSG code\n",
    "raster_image_epsg_code = raster_image.crs.to_epsg()\n",
    "if raster_image_epsg_code:\n",
    "    raster_image_projection_name = get_projection_name(raster_image_epsg_code)\n",
    "    print(f\"The projection name for the raster image with EPSG code {raster_image_epsg_code} is, {raster_image_projection_name}.\\n\")\n",
    "else:\n",
    "    print('The raster image CRS does not have an EPSG code.')\n",
    "\n",
    "# Check if projections match\n",
    "if shp.crs != raster_image.crs:\n",
    "    print('Projections do not match.')\n",
    "else:\n",
    "    print('Projections match.')\n",
    "    \n",
    "# Get raster extent\n",
    "raster_extent = [raster_image.bounds[0], raster_image.bounds[2], raster_image.bounds[1], raster_image.bounds[3]]\n",
    "\n",
    "# Create a new plot\n",
    "f, ax = plt.subplots()\n",
    "\n",
    "# Render image\n",
    "show(\n",
    "    tiff_band_1,\n",
    "    extent=raster_extent,\n",
    "    ax=ax,\n",
    ")\n",
    "\n",
    "# Add shapefile\n",
    "shp.plot(ax=ax, facecolor='w', edgecolor='k')\n",
    "ax.axis('off')\n",
    "ax.set_title('Projection Check')\n",
    "\n",
    "# Save image to output folder\n",
    "figure_filename = f\"{formatted_datetime}_Job_ID_{job_id}_PFI_{pfi}_Planet_NDVI_time_series.jpg\"\n",
    "figure_save_file_path = os.path.join(output_path, figure_filename)\n",
    "plt.savefig (figure_save_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop through images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Initialise empty DataFrame\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# Record start\n",
    "start_time = datetime.datetime.now()\n",
    "print(\"Starting at \" + start_time.strftime(\"%d/%m/%Y, %H:%M:%S\"))\n",
    "\n",
    "# Time variables\n",
    "start_time_str = start_time.strftime(\"%d/%m/%Y, %H:%M:%S\")\n",
    "\n",
    "# Loop through image folder\n",
    "for image_file in image_files:\n",
    "    # Get base image name\n",
    "    image_name = os.path.basename(image_file)\n",
    "    # UDM file name\n",
    "    udm_file = image_file.replace('AnalyticMS_SR', 'udm2').replace('AnalyticMS', 'udm2')\n",
    "    \n",
    "    # Convert the image file timestamp from UTC to AEST\n",
    "    aest_file_timestamp , aest_date = filename_utc_to_aest(image_name)    \n",
    "\n",
    "    # Prepend the converted timestamp to the original filename\n",
    "    output_image_name = f\"{aest_file_timestamp}_AEST_{image_name}\"\n",
    "    \n",
    "    # Get image date\n",
    "    image_date = image_name[:8]\n",
    "    image_date = dt.strptime(image_date, '%Y%m%d').strftime('%d/%m/%Y')\n",
    "\n",
    "    # Clip image and get the clipped image data and metadata in memory\n",
    "    clipped_data, clipped_meta = clip_raster_to_shapefile(image_file, aoi)\n",
    "\n",
    "    # Assume nodata as None before getting the actual value from metadata\n",
    "    nodata = None\n",
    "    \n",
    "    # Clip AOI to buffer\n",
    "    shp = gpd.read_file(aoi)\n",
    "    \n",
    "    # Open the image with rasterio\n",
    "    with rasterio.open(image_file) as src:\n",
    "        # Buffer the AOI and then clip\n",
    "        buffered_aoi = shp.geometry.buffer(buffer_distance)\n",
    "        out_image, out_transform = rasterio.mask.mask(src, buffered_aoi, crop=True)\n",
    "        out_meta = src.meta.copy()\n",
    "        out_meta.update({\n",
    "            \"driver\": \"GTiff\",\n",
    "            \"height\": out_image.shape[1],\n",
    "            \"width\": out_image.shape[2],\n",
    "            \"transform\": out_transform\n",
    "        })\n",
    "\n",
    "        # Define the output filename using your naming convention\n",
    "        buffered_output = os.path.join(output_path, f\"{output_image_name}_RGB_Buffered.tif\")\n",
    "        \n",
    "        # Save the buffered RGB clip to a new GeoTIFF file\n",
    "        with rasterio.open(buffered_output, \"w\", **out_meta) as dest:\n",
    "            dest.write(out_image)    \n",
    "\n",
    "    print(\"\\nProcessing date: \" + image_date)\n",
    "\n",
    "    # print(\"Image name: \" + image_name)\n",
    "    # print('UDM file: ', udm_file)\n",
    "    with MemoryFile() as memfile:\n",
    "        with memfile.open(**clipped_meta) as dataset:\n",
    "            # Retrieve the nodata value from the dataset\n",
    "            nodata = dataset.nodata\n",
    "            \n",
    "            # print(f\"Clipped Data Shape: {dataset.shape}\")  # (height, width)\n",
    "            # print(f\"Clipped Data Transform: {dataset.transform}\")\n",
    "\n",
    "            # Write the raster data to the dataset\n",
    "            dataset.write(clipped_data)\n",
    "\n",
    "            # Now, perform operations using the dataset as a proxy to the data\n",
    "            # abs to return only positive values that make sense to user\n",
    "            transform = dataset.transform\n",
    "            x_res = abs(transform.a) # Resolution in x direction (transform[0])\n",
    "            y_res = abs(transform.e)  # Resolution in y direction (transform[4])\n",
    "            pixel_area_m2 = (x_res * y_res) \n",
    "            \n",
    "            # Load red and NIR bands for NDVI calculation\n",
    "            bandred = dataset.read(3).astype(float)\n",
    "            bandnir = dataset.read(4).astype(float)    \n",
    "\n",
    "            # Allow division by zero\n",
    "            np.seterr(divide='ignore', invalid='ignore')\n",
    "            \n",
    "            # Ensures 'ndvi_threshold' is a number.\n",
    "            if ndvi_threshold is None:\n",
    "                raise ValueError(\"NDVI threshold is 'None', expected a float.\")\n",
    "\n",
    "            # Ensures 'bandred' and 'bandnir' contain no 'None' values.\n",
    "            if np.any(bandred == None) or np.any(bandnir == None):\n",
    "                raise ValueError(\"Band arrays contain 'None' values, expected only numerical data.\")            \n",
    "\n",
    "            # Calculate NDVI\n",
    "            ndvi = (bandnir - bandred) / (bandnir + bandred)\n",
    "            \n",
    "            total_valid_area, below_threshold_area, percentage_below_threshold, above_threshold_area, percentage_above_threshold = measure_areas(ndvi, ndvi_threshold, pixel_area_m2)\n",
    "\n",
    "            # Define nodata value\n",
    "            nodata = 0\n",
    "            # nodata = dataset.nodata if dataset.nodata is not None else 0\n",
    "\n",
    "            # Perform classification ##### (<= Negative NDVI, else >= NDVI) #####\n",
    "            classified = np.where(ndvi <= ndvi_threshold, 1, nodata).astype(np.uint8)\n",
    "            # print(f\"Classified Min: {classified.min()}, Max: {classified.max()}\")\n",
    "\n",
    "            # Create a colormap (0: transparent, 1: blue)\n",
    "            colormap = {0: (0, 0, 0, 0), 1: (0, 0, 255, 255)}\n",
    "            \n",
    "            # Define metadata for the new single-band GeoTIFF with classification\n",
    "            out_meta = dataset.meta.copy()\n",
    "            out_meta.update({\n",
    "                'driver': 'GTiff',\n",
    "                'dtype': 'uint8',\n",
    "                'count': 1,\n",
    "                'compress': 'lzw',\n",
    "                'nodata': nodata,\n",
    "                'photometric': 'RGBA'\n",
    "            })\n",
    "\n",
    "        # Print and check dimensions and transform before writing\n",
    "        # print(f\"Writing Classified Raster with Size: {classified.shape}\")  # Should match dataset.shape\n",
    "        # print(f\"Output Data Transform: {out_meta['transform']}\")\n",
    "\n",
    "        # Before writing, check dimensions and potential issues\n",
    "        if classified.shape != (dataset.height, dataset.width):\n",
    "            print(\"Error: Classified raster dimensions do not match dataset dimensions.\")\n",
    "        elif classified.max() == nodata:\n",
    "            print(\"Error: All classified raster values are nodata.\")\n",
    "        \n",
    "        # Define the output path\n",
    "        classified_output = os.path.join(output_path, f\"{output_image_name}_Threshold_{ndvi_threshold}_NDVI_Classified.tif\")  # Use os.path.join for cross-platform compatibility\n",
    "\n",
    "        # Set spatial characteristics of the output object to mirror the input\n",
    "        kwargs = dataset.meta\n",
    "        kwargs.update(\n",
    "        dtype=rasterio.float32,\n",
    "        count = 1\n",
    "        )\n",
    "\n",
    "        # Write out the classified raster with colormap applied\n",
    "        with rasterio.open(classified_output, 'w', **out_meta) as dst:\n",
    "            dst.write(classified, 1)\n",
    "            dst.write_colormap(1, colormap)\n",
    "        \n",
    "        \n",
    "            # Read UDM file for cloud, haze, and shadow\n",
    "            # Define metadata for a new single-band GeoTIFF\n",
    "            ndvi_meta = dataset.meta.copy()\n",
    "            ndvi_meta.update({\n",
    "                'dtype': 'uint8',\n",
    "                'count': 1,\n",
    "                'compress': 'lzw',\n",
    "                'nodata': 0  # Set the nodata value as required\n",
    "            })\n",
    "            \n",
    "            # Clip the UDM file\n",
    "            with rasterio.open(udm_file) as src:\n",
    "                cloud_mask = src.read(6).astype(bool) # cloud is 6th band (index 5)\n",
    "                haze_mask = src.read(4).astype(bool) # haze is 4th band (index 3)\n",
    "                shadow_mask = src.read(3).astype(bool) # shadow is 3rd band (index 2)\n",
    "                extent = rasterio.plot.plotting_extent(src)\n",
    "\n",
    "            # Use rasterio's geometry mask to clip the UDM to the area of interest\n",
    "            with rasterio.open(udm_file) as src:\n",
    "                out_image, out_transform = rasterio.mask.mask(src, shp.geometry, crop=True)\n",
    "                out_meta = src.meta.copy()\n",
    "                out_meta.update({'driver': 'GTiff',\n",
    "                                'height': out_image.shape[1],\n",
    "                                'width': out_image.shape[2],\n",
    "                                'transform': out_transform})\n",
    "                \n",
    "                # Calculate the covered area for each mask\n",
    "                cloud_covered_area = calculate_covered_area(out_image[5], out_meta, shp)\n",
    "                haze_covered_area = calculate_covered_area(out_image[3], out_meta, shp)\n",
    "                shadow_covered_area = calculate_covered_area(out_image[2], out_meta, shp)\n",
    "\n",
    "                # Calculate cover percentages\n",
    "                cloud_covered_percentage = (cloud_covered_area / total_valid_area) * 100\n",
    "                haze_covered_percentage = (haze_covered_area / total_valid_area) * 100\n",
    "                shadow_covered_percentage = (shadow_covered_area / total_valid_area) * 100\n",
    "\n",
    "                # Print the results\n",
    "                # print(f\"Total area (sqm): {total_valid_area}\")\n",
    "                # print(f\"Cloud covered area (sqm): {cloud_covered_area}\")\n",
    "                # print(f\"Haze covered area (sqm): {haze_covered_area}\")\n",
    "                # print(f\"Shadow covered area (sqm): {shadow_covered_area}\")\n",
    "\n",
    "                # Print cover percentages\n",
    "                print(f\"Cloud covered %: {cloud_covered_percentage}\")\n",
    "                print(f\"Haze covered %: {haze_covered_percentage}\")\n",
    "                print(f\"Shadow covered %: {shadow_covered_percentage}\")\n",
    "\n",
    "    # Define kwargs here\n",
    "    kwargs = dataset.meta.copy()\n",
    "    kwargs.update(\n",
    "        dtype=rasterio.float32,\n",
    "        count=1)\n",
    "    \n",
    "    # Write out NDVI GeoTIFF image\n",
    "    ndvi_output = output_path + \"\\\\\" + output_image_name + \"_NDVI.tif\"\n",
    "    with rasterio.open(ndvi_output, 'w', **kwargs) as dst:\n",
    "        dst.write_band(1, ndvi.astype(rasterio.float32))   \n",
    "\n",
    "    # Prepare the appropriate metadata\n",
    "    out_meta = dataset.meta.copy()\n",
    "    out_meta.update({\n",
    "        'driver': 'GTiff',\n",
    "        'height': classified.shape[0],  # Update to match classification array's height\n",
    "        'width': classified.shape[1],   # Update to match classification array's width\n",
    "        'transform': dataset.transform, # Update if you've altered the transform\n",
    "        'dtype': 'uint8',\n",
    "        'count': 1,  # Single-band raster\n",
    "        'compress': 'lzw',\n",
    "        'nodata': nodata  # Nodata value\n",
    "    })\n",
    "    \n",
    "    # print(image_date)\n",
    "    \n",
    "    # Use NumPy to mask out invalid pixels\n",
    "    ndvi_masked = np.ma.masked_invalid(ndvi)\n",
    "    \n",
    "    # Define the dimensions of the image\n",
    "    ndvi_shape = ndvi_masked.shape\n",
    "\n",
    "    # Create the plot area\n",
    "    fig, ax = plt.subplots(figsize=(12, 12))\n",
    "\n",
    "    # Create a new figure with the same dimensions as ndvi_masked\n",
    "    fig = Figure(figsize=(ndvi_shape[1]/fig.dpi, ndvi_shape[0]/fig.dpi), dpi=fig.dpi)\n",
    "    canvas = FigureCanvasAgg(fig)\n",
    "    ax = fig.add_axes([0, 0, 1, 1])  # Add an axis that covers the entire figure\n",
    "\n",
    "    # Show the masked NDVI image without padding and without axes\n",
    "    ax.imshow(ndvi_masked, cmap=colour_map)\n",
    "    ax.axis('off')\n",
    "\n",
    "    # Add your image_date text to the image at the top-left corner\n",
    "    timestamp_with_timezone = f\"{aest_file_timestamp} AEST\"  # Append 'AEST' to the timestamp\n",
    "    text_props = dict(boxstyle='round', facecolor='black', alpha=0.5)\n",
    "    ax.text(0.01, 0.99, timestamp_with_timezone, transform=ax.transAxes, fontsize=12, color='white', bbox=text_props, verticalalignment='top', horizontalalignment='left')\n",
    "\n",
    "    # Save the figure to a file with the given path and name\n",
    "    output_file_path = f\"{output_path}\\\\{output_image_name}_NDVI_Colour.png\"\n",
    "    fig.savefig(output_file_path, dpi=fig.dpi, bbox_inches='tight', pad_inches=0, transparent=True)\n",
    "\n",
    "    # We no longer need the figure after saving it, free the memory\n",
    "    plt.close(fig)\n",
    "    \n",
    "    # Gather statistics\n",
    "    bandred_min = np.nanmin(bandred)\n",
    "    bandred_max = np.nanmax(bandred)\n",
    "    bandred_mean = np.nanmean(bandred)\n",
    "           \n",
    "    bandnir_min = np.nanmin(bandnir)\n",
    "    bandnir_max = np.nanmax(bandnir)\n",
    "    bandnir_mean = np.nanmean(bandnir)\n",
    "               \n",
    "    ndvi_min = np.nanmin(ndvi)\n",
    "    ndvi_max = np.nanmax(ndvi)\n",
    "    ndvi_mean = np.nanmean(ndvi)\n",
    "        \n",
    "    # Append results to DataFrame\n",
    "    new_row = pd.DataFrame({\n",
    "        \"Image Name\": [output_image_name + \"_NDVI.tif\"],\n",
    "        \"Image Date AEST\": [aest_date],\n",
    "        \"Total Area (sqm)\": [total_valid_area],\n",
    "        \"Total Area (ha)\": [total_valid_area/10000],\n",
    "        \"NDVI Area (sqm)\": [above_threshold_area],\n",
    "        \"NDVI Area (ha)\": [above_threshold_area/10000],\n",
    "        \"NDVI %\": [percentage_above_threshold],\n",
    "        \"-NDVI Area (ha)\": [(total_valid_area-above_threshold_area)/10000],\n",
    "        \"-NDVI %\": [100-percentage_above_threshold],\n",
    "        \"Cloud Coverage\": [cloud_covered_area],\n",
    "        \"Cloud %\": [cloud_covered_percentage],\n",
    "        \"Haze (sqm)\": [haze_covered_area],\n",
    "        \"Haze %\": [haze_covered_percentage],\n",
    "        \"Shadow (sqm)\": [shadow_covered_area],\n",
    "        \"Shadow %\": [shadow_covered_percentage],\n",
    "        \"NDVI Min\": [ndvi_min],\n",
    "        \"NDVI Max\": [ndvi_max],\n",
    "        \"NDVI Mean\": [ndvi_mean],\n",
    "        \"Red Band Min\": [bandred_min],\n",
    "        \"Red Band Max\": [bandred_max],\n",
    "        \"Red Band Mean\": [bandred_mean],\n",
    "        \"NIR Band Min\": [bandnir_min],\n",
    "        \"NIR Band Max\": [bandnir_max],\n",
    "        \"NIR Band Mean\": [bandnir_mean],\n",
    "    })\n",
    "    df = pd.concat([df, new_row], ignore_index=False)\n",
    "\n",
    "# Record end\n",
    "end_time = datetime.datetime.now()\n",
    "end_time_str = end_time.strftime(\"%d/%m/%Y, %H:%M:%S\")\n",
    "\n",
    "# Calculate processing time\n",
    "processing_time = end_time - start_time\n",
    "processing_time_str = str(processing_time)\n",
    "\n",
    "print(\"\\nEntire period processed, started at \" + start_time_str + \" and finished at \" + end_time_str + \".\\n\")\n",
    "print(\"Total processing time: \" + processing_time_str + \".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write metadata outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with process metadata\n",
    "metadata_df = pd.DataFrame({\n",
    "    \"Variable Name\": [\"Job ID\",\n",
    "                      \"PFI\",\n",
    "                      \"Analyst\",\n",
    "                      \"NDVI Threshold\",\n",
    "                      \"Matplotlib Colourmap\",\n",
    "                      \"Start Date and Time\",\n",
    "                      \"End Date and Time\",\n",
    "                      \"Total Time HH:MM:SS.ss\",\n",
    "                      \"Shapefile EPSG Code\",\n",
    "                      \"Shapefile Projection Name\",\n",
    "                      \"Raster EPSG Code\",\n",
    "                      \"Raster Projection Name\",\n",
    "                      \"X Pixel Resolution (m)\",\n",
    "                      \"Y Pixel Resolution (m)\",\n",
    "                      \"Pixel Area (sqm)\",\n",
    "                      \"Source Imagery\",\n",
    "                      \"Source Shapefile\",\n",
    "                      \"Output Folder\",\n",
    "                      \"Software Version\",\n",
    "                      \"Python Version\",\n",
    "                      \"Python Environment\"],\n",
    "    \"Value\": [job_id,\n",
    "                pfi,\n",
    "                analyst,\n",
    "                ndvi_threshold,\n",
    "                colour_map,\n",
    "                start_time_str,\n",
    "                end_time_str,\n",
    "                processing_time_str,\n",
    "                shp_epsg_code,\n",
    "                shp_projection_name,\n",
    "                raster_image_epsg_code,\n",
    "                raster_image_projection_name,\n",
    "                x_res,\n",
    "                y_res,\n",
    "                pixel_area_m2,\n",
    "                base_dir,\n",
    "                aoi,\n",
    "                output_path,\n",
    "                software_version,\n",
    "                python_version,\n",
    "                python_environment]\n",
    "})\n",
    "\n",
    "# Create a dictionary to store the module names and versions\n",
    "module_versions = {}\n",
    "\n",
    "# Iterate over the modules dictionary in and get the module name and version\n",
    "for module_name, module in modules.items():\n",
    "    try:\n",
    "        if module_name == 'Python':\n",
    "            version = sys.version.split()[0]\n",
    "        else:\n",
    "            version = module.__version__\n",
    "    except AttributeError:\n",
    "        version = 'Same as Python version'\n",
    "    module_versions[module_name] = version\n",
    "\n",
    "# Create a pandas DataFrame from the dictionary\n",
    "modules_df = pd.DataFrame(list(module_versions.items()), columns=['Module', 'Version'])\n",
    "\n",
    "# ExcelWriter to create an Excel output, add NDVI Output, Job Metadata, and Python Modules tabs\n",
    "writer = pd.ExcelWriter(excel_file_path, engine=\"xlsxwriter\")\n",
    "workbook = writer.book\n",
    "\n",
    "# Add Job NDVI Output tab\n",
    "df.to_excel(writer, sheet_name=\"NDVI Output\", index=False)\n",
    "# NDVI Output worksheet\n",
    "ndvi_output_worksheet = writer.sheets['NDVI Output']\n",
    "ndvi_output_worksheet.autofit()\n",
    "\n",
    "# Add Job Metadata tab\n",
    "metadata_df.to_excel(writer, sheet_name='Job Metadata', index=False, header=False)\n",
    "# Job Metadata worksheet\n",
    "metadata_worksheet = writer.sheets['Job Metadata']\n",
    "left_align_format = workbook.add_format({'align': 'left'})\n",
    "metadata_worksheet.set_column('B:B', None, left_align_format)\n",
    "metadata_worksheet.autofit() \n",
    "# Add Python module versions\n",
    "modules_df.to_excel(writer, sheet_name='Python Modules', index=False, header=False)\n",
    "# Python Modules worksheet\n",
    "python_modules_worksheet = writer.sheets['Python Modules']\n",
    "python_modules_worksheet.autofit()\n",
    "\n",
    "# Close the Pandas ExcelWriter and save the Excel file\n",
    "writer.close()\n",
    "\n",
    "print('Excel spreadsheet containing job information is here:\\n')\n",
    "print('Excel file path:', excel_file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
