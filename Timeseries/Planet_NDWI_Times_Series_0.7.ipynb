{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Planet NDWI time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This script is designed to process 4 band multispectral\n",
    "# satellite images from Planet Labs to calculate the \n",
    "# Normalised Difference Water Index (NDWI).\n",
    "\n",
    "# This Python script is setup to calculate the water surface area (WSA) of water\n",
    "# on the landscape, LotPlan, or targeted at individual waterbodies\n",
    "\n",
    "\n",
    "# Planet imagery across Queensland is covered by 3 UTM zones\n",
    "# Ensure your AOI projection matches your imagery\n",
    "\n",
    "# UTM Zone 54S: This zone covers the easternmost part of \n",
    "# Queensland, including the eastern coast and cities such as Cairns.\n",
    "\n",
    "# UTM Zone 55S: Most of central Queensland falls under this zone.\n",
    "\n",
    "# UTM Zone 56S: The vast majority of southeastern Queensland,\n",
    "# including Brisbane and the Gold Coast, is within this zone.\n",
    "\n",
    "# 14/05/2025\n",
    "\n",
    "# Remote Sensing\n",
    "# remotesensing@dlgwv.qld.gov.au\n",
    "\n",
    "# Craig Turner\n",
    "# craig.turner@dlgwv.qld.gov.au \n",
    " \n",
    "# Department of Local Government, Water, and Volunteers\n",
    "# Water Operations & Systems\n",
    "# Programs Knowledge and Systems Initiatives\n",
    "# Digital Systems and Solutions\n",
    "\n",
    "software_version = 0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add any additional modules to Version information list below\n",
    "\n",
    "# Standard imports\n",
    "import datetime\n",
    "from datetime import datetime as dt\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Third-party imports\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')  # Prevent inline display of imagery\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.figure import Figure\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg\n",
    "from PIL import Image, ImageTk\n",
    "import pytz\n",
    "from pyproj import CRS\n",
    "import rasterio\n",
    "from rasterio.io import MemoryFile\n",
    "from rasterio.mask import mask\n",
    "from rasterio.plot import show\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog, messagebox, Label, Tk, ttk\n",
    "import xlsxwriter\n",
    "from xlsxwriter.workbook import Workbook\n",
    "\n",
    "# Version information list\n",
    "modules = {\n",
    "    'datetime': datetime,\n",
    "    'os': os,\n",
    "    'sys': sys,\n",
    "    'glob': glob,\n",
    "    'NumPy': np,\n",
    "    'pandas': pd,\n",
    "    'GeoPandas': gpd,\n",
    "    'Maplotlib': plt,    \n",
    "    'PIL': Image,\n",
    "    'pytz': pytz,\n",
    "    'pyproj': CRS,\n",
    "    'rasterio': rasterio,\n",
    "    'tkinter': tk,\n",
    "    'XlsxWriter': xlsxwriter\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declare functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to calculate the covered area in square metres\n",
    "def calculate_covered_area(udm_band, udm_meta, aoi):\n",
    "    # Transform the pixel coordinates to the geographic coordinates\n",
    "    transform = udm_meta['transform']\n",
    "    \n",
    "    # Count the number of pixels that are True within the mask (indicating presence of cloud/haze/shadow)\n",
    "    pixel_area = (transform[0] * -transform[4])  # The area of a pixel in sqm\n",
    "    covered_pixels = udm_band.sum()\n",
    "    covered_area_sqm = covered_pixels * pixel_area\n",
    "    \n",
    "    return covered_area_sqm\n",
    "\n",
    "# Function to clip raster to shapefile\n",
    "def clip_raster_to_shapefile(raster_file, shapefile):\n",
    "    # Load the boundaries of the clip shapefile using geopandas\n",
    "    shp = gpd.read_file(shapefile)\n",
    "    \n",
    "    # Open the source raster using rasterio\n",
    "    with rasterio.open(raster_file) as src:\n",
    "        # Clip the raster with the shapefile using a mask\n",
    "        out_image, out_transform = mask(src, shp.geometry, crop=True)\n",
    "        # Copy and update the metadata for the clipped raster\n",
    "        out_meta = src.meta\n",
    "        out_meta.update({\n",
    "            \"height\": out_image.shape[1],\n",
    "            \"width\": out_image.shape[2],\n",
    "            \"transform\": out_transform\n",
    "        })\n",
    "    \n",
    "    # Return the in-memory clipped raster data and the updated metadata\n",
    "    return out_image, out_meta    \n",
    "    \n",
    "# Function to classify raster into two classes based on a threshold\n",
    "def classify_raster(raster_file, threshold, output_file):\n",
    "    with rasterio.open(raster_file) as src:\n",
    "        # Read raster band 1\n",
    "        band1 = src.read(1)\n",
    "\n",
    "        # Apply classification based on threshold\n",
    "        classified = np.where(band1 > threshold, 0, 1).astype(np.uint8)\n",
    "\n",
    "        # Check for existing nodata value in the raster's metadata\n",
    "        nodata = src.nodata\n",
    "        if nodata is None:\n",
    "            nodata = 0  # Default to 0 or another appropriate nodata value for your dataset\n",
    "\n",
    "        # Apply the classification\n",
    "        classified = np.where(band1 > threshold, 1, nodata).astype(np.uint8)\n",
    "\n",
    "        # Update metadata for output\n",
    "        out_meta = src.meta.copy()\n",
    "        out_meta.update({\n",
    "            \"driver\": \"GTiff\",\n",
    "            \"dtype\": \"uint8\",\n",
    "            \"nodata\": nodata,\n",
    "            \"count\": 1,\n",
    "            \"compress\": \"lzw\"\n",
    "        })\n",
    "\n",
    "    # Write out the raster\n",
    "    with rasterio.open(output_file, \"w\", **out_meta) as dest:\n",
    "        dest.write(classified, 1)\n",
    "\n",
    "# Function to calculate area\n",
    "def measure_areas(masked_raster_band, threshold, pixel_area_m2):\n",
    "    # Mask for valid data (non-NaN values)\n",
    "    valid_data_mask = ~np.isnan(masked_raster_band)\n",
    "\n",
    "    # Masks for areas above and below the threshold\n",
    "    above_threshold_mask = (masked_raster_band >= threshold) & valid_data_mask\n",
    "    below_threshold_mask = (masked_raster_band < threshold) & valid_data_mask\n",
    "    \n",
    "    # Calculate areas for above and below threshold\n",
    "    above_threshold_area = np.sum(above_threshold_mask) * pixel_area_m2\n",
    "    below_threshold_area = np.sum(below_threshold_mask) * pixel_area_m2\n",
    "\n",
    "    # Calculate the total valid area\n",
    "    total_valid_area = above_threshold_area + below_threshold_area\n",
    "\n",
    "    # Calculating the percentages\n",
    "    percentage_above_threshold = (above_threshold_area / total_valid_area) * 100 if total_valid_area != 0 else 0\n",
    "    percentage_below_threshold = (below_threshold_area / total_valid_area) * 100 if total_valid_area != 0 else 0\n",
    "\n",
    "    return total_valid_area, below_threshold_area, percentage_below_threshold, above_threshold_area, percentage_above_threshold\n",
    "\n",
    "# Function to retrieve projection human readable name\n",
    "def get_projection_name(epsg_code):\n",
    "    crs = CRS.from_epsg(epsg_code)\n",
    "    return crs.name\n",
    "\n",
    "# Convert UTC time in filename to AEST (UTC+10:00)\n",
    "def filename_utc_to_aest(filename):\n",
    "    # Extract the timestamp from the filename, assume the format is: YYYYMMDD_HHMMSS\n",
    "    file_timestamp_str = filename.split('_')[1]\n",
    "    # Assuming the date is at the beginning of the filename '20231118'\n",
    "    file_date_str = filename.split('_')[0]\n",
    "    file_datetime_str = file_date_str + '_' + file_timestamp_str\n",
    "\n",
    "    # Create a datetime object\n",
    "    file_datetime = dt.strptime(file_datetime_str, \"%Y%m%d_%H%M%S\")\n",
    "\n",
    "    # Timezone conversion from UTC to AEST\n",
    "    local_tz = pytz.timezone('Australia/Brisbane')\n",
    "    local_dt = file_datetime.replace(tzinfo=pytz.utc).astimezone(local_tz)\n",
    "\n",
    "    # Format the datetime object to a string for full AEST timestamp\n",
    "    local_dt_full_str = local_dt.strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "    # Format the datetime object to a string for just the date portion\n",
    "    local_dt_date_str = local_dt.strftime('%d/%m/%Y')\n",
    "\n",
    "    return local_dt_full_str, local_dt_date_str\n",
    "\n",
    "# GUI stuff\n",
    "class PlaceholderEntry(tk.Entry):\n",
    "    def __init__(self, master=None, placeholder=\"PLACEHOLDER\", color='grey', **kwargs):\n",
    "        super().__init__(master=master, **kwargs)\n",
    "        self.placeholder = placeholder\n",
    "        self.placeholder_color = color\n",
    "        self.default_fg_color = self['fg']\n",
    "\n",
    "        self.bind(\"<FocusIn>\", self.foc_in)\n",
    "        self.bind(\"<FocusOut>\", self.foc_out)\n",
    "\n",
    "        self.put_placeholder()\n",
    "\n",
    "    def put_placeholder(self):\n",
    "        self.insert(0, self.placeholder)\n",
    "        self['fg'] = self.placeholder_color\n",
    "\n",
    "    def foc_in(self, *args):\n",
    "        if self.get() == self.placeholder and self['fg'] == self.placeholder_color:\n",
    "            self.delete('0', 'end')\n",
    "            self['fg'] = self.default_fg_color\n",
    "\n",
    "    def foc_out(self, *args):\n",
    "        if not self.get():\n",
    "            self.put_placeholder()\n",
    "\n",
    "def selection_changed(event):\n",
    "    print(\"Selected:\", combobox.get())\n",
    "\n",
    "def select_file(entry_widget):\n",
    "    # Define the file type filter\n",
    "    filetypes = (\n",
    "        ('Shapefiles', '*.shp'),\n",
    "    )\n",
    "\n",
    "    # Open file dialog with .shp filter\n",
    "    file_path = filedialog.askopenfilename(title=\"Select file\", filetypes=filetypes)\n",
    "\n",
    "    # Check if a file was selected\n",
    "    if file_path:\n",
    "        entry_widget.delete(0, tk.END)  # Remove any existing text in the entry\n",
    "        entry_widget.insert(0, file_path)  # Insert the selected path\n",
    "\n",
    "def select_directory(entry_widget):\n",
    "    directory_path = filedialog.askdirectory(title=\"Select directory\")\n",
    "    entry_widget.delete(0, tk.END)\n",
    "    entry_widget.insert(0, directory_path)\n",
    "\n",
    "def submit_form():\n",
    "    # Define global variables to store the form data\n",
    "    global job_id, pfi, analyst, ndwi_threshold, colour_map, base_dir, aoi, gui_path\n",
    "\n",
    "    job_id = field1_entry.get()\n",
    "    pfi = field2_entry.get()\n",
    "    analyst = name_combobox.get()\n",
    "    colour_map = colourmap_combobox.get()\n",
    "    base_dir = source1_entry.get()\n",
    "    aoi = source2_entry.get()\n",
    "    gui_path = output1_entry.get()\n",
    "\n",
    "    # Get the NDWI threshold as string and then convert it to a float after stripping whitespace.\n",
    "    ndwi_threshold_str = field4_entry.get().strip()\n",
    "\n",
    "    try:\n",
    "        # Convert the threshold value to float and check its range.\n",
    "        ndwi_threshold = float(ndwi_threshold_str)\n",
    "        if not -1.0 <= ndwi_threshold <= 1.0:\n",
    "            messagebox.showerror(\"Input Error\", \"Invalid NDWI Threshold value. Please enter a value between -1 and 1.\")\n",
    "            return\n",
    "    except ValueError:\n",
    "        messagebox.showerror(\"Input Error\", \"Invalid NDWI Threshold value. Please enter a numerical value.\")\n",
    "        return\n",
    "    \n",
    "    # After submitting the form and processing the data without any errors, close the GUI.\n",
    "    root.destroy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GUI - Create output folder - Set variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected str, bytes or os.PathLike object, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 112\u001b[0m\n\u001b[0;32m    109\u001b[0m root\u001b[38;5;241m.\u001b[39mmainloop()\n\u001b[0;32m    111\u001b[0m \u001b[38;5;66;03m# Only read analytical imagery\u001b[39;00m\n\u001b[1;32m--> 112\u001b[0m image_files \u001b[38;5;241m=\u001b[39m glob\u001b[38;5;241m.\u001b[39mglob(\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m*Analytic*.tif\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;66;03m# Get current date and time\u001b[39;00m\n\u001b[0;32m    115\u001b[0m current_datetime \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow()\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\RemoteSensingPlanet\\lib\\ntpath.py:78\u001b[0m, in \u001b[0;36mjoin\u001b[1;34m(path, *paths)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mjoin\u001b[39m(path, \u001b[38;5;241m*\u001b[39mpaths):\n\u001b[1;32m---> 78\u001b[0m     path \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     79\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[0;32m     80\u001b[0m         sep \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[1;31mTypeError\u001b[0m: expected str, bytes or os.PathLike object, not NoneType"
     ]
    }
   ],
   "source": [
    "# Clear input variables\n",
    "job_id = None\n",
    "pfi = None\n",
    "analyst = None\n",
    "ndwi_threshold = None\n",
    "colour_map = None \n",
    "base_dir = None\n",
    "aoi = None\n",
    "gui_path = None\n",
    "\n",
    "# Option lists\n",
    "colour_map_options = ['viridis', 'plasma', 'inferno', 'magma', 'cividis', \n",
    "                      'viridis_r', 'plasma_r', 'inferno_r', 'magma_r', 'cividis_r']\n",
    "name_options = ['Jason Dechastel', 'Lasinidu Jayarathna', 'Eva Kovaks', 'Craig Turner']\n",
    "\n",
    "# Create corporate colours\n",
    "Cybernetic = \"#275c6d\"  # Primary\n",
    "Prosperity = \"#077297\"  # Secondary\n",
    "Bold_Blue = \"#023a57\"   # Secondary\n",
    "\n",
    "Mangrove = \"#4b623b\"    # Primary\n",
    "Waterhole = \"#a69b5e\"   # Secondary\n",
    "H20 = \"#315450\"         # Secondary\n",
    "\n",
    "Terrain = \"#8c4d36\"     # Primary\n",
    "Ochre = \"#ac6d29\"       # Secondary\n",
    "Sunrise = \"#c48c33\"     # Secondary\n",
    "\n",
    "# Assign colours\n",
    "main_bg_colour =  Prosperity \n",
    "frame_bg_colour = Cybernetic\n",
    "label_bg_colour = Cybernetic\n",
    "entry_bg_colour = \"black\" # Not currently used\n",
    "button_bg_colour = \"white\"  # Not currently used\n",
    "\n",
    "# Main window creation and setup\n",
    "root = tk.Tk()\n",
    "root.title(\"Planet NDWI time series\")\n",
    "root.configure(bg=main_bg_colour)\n",
    "root.attributes('-topmost', True)\n",
    "               \n",
    "# Load an image using PIL\n",
    "image_path = 'Qld-CoA-Stylised-1L-mono_rev.png'\n",
    "image = Image.open(image_path)\n",
    "photo = ImageTk.PhotoImage(image)\n",
    "\n",
    "# Create a frame to hold the image and the title\n",
    "header_frame = tk.Frame(root, bg = frame_bg_colour)\n",
    "header_frame.grid(row=0, column=0, columnspan=3, sticky=\"nw\", padx=5, pady=5)\n",
    "\n",
    "# Display Queensland Coat of Arms in the top-left corner of the GUI\n",
    "image_label = tk.Label(header_frame, image=photo, bg=frame_bg_colour)\n",
    "image_label.grid(row=0, column=0, sticky=\"nw\")\n",
    "\n",
    "# Display title to the right of the Queensland Coat of Arms\n",
    "title_label = tk.Label(header_frame, text=\"Planet NDWI time series\\n \\nDigital Systems and Solutions \", font=(\"Arial\", 22), fg=\"#ffffff\", bg=label_bg_colour)\n",
    "title_label.grid(row=0, column=1, sticky=\"w\")\n",
    "\n",
    "# Create labels and entry widgets for each field with placeholders\n",
    "tk.Label(root, text=\"Job ID:\").grid(row=1, column=0, sticky=\"e\")\n",
    "field1_entry = PlaceholderEntry(root, placeholder=\"e.g., 231132\", width=28)\n",
    "field1_entry.grid(row=1, column=1, padx=5, pady=5, sticky=\"w\")\n",
    "\n",
    "tk.Label(root, text=\"PFI:\").grid(row=2, column=0, sticky=\"e\")\n",
    "field2_entry = PlaceholderEntry(root, placeholder=\"Persistent Feature Identifier\", width=28)\n",
    "field2_entry.grid(row=2, column=1, padx=5, pady=5, sticky=\"w\")\n",
    "\n",
    "ttk.Label(root, text=\"Name:\").grid(row=3, column=0, sticky=\"e\")\n",
    "name_combobox = ttk.Combobox(root, values=name_options, width=25)\n",
    "name_combobox.grid(row=3, column=1, padx=5, pady=5, sticky=\"w\")\n",
    "\n",
    "tk.Label(root, text=\"NDWI Threshold:\").grid(row=4, column=0, sticky=\"e\")\n",
    "field4_entry = PlaceholderEntry(root, placeholder=\"-1 to 1\", width=28)\n",
    "field4_entry.grid(row=4, column=1, padx=5, pady=5, sticky=\"w\")\n",
    "\n",
    "ttk.Label(root, text=\"Matplotlib colourmap:\").grid(row=5, column=0, sticky=\"e\")\n",
    "colourmap_combobox = ttk.Combobox(root, values=colour_map_options, width=25)\n",
    "colourmap_combobox.grid(row=5, column=1, padx=5, pady=5, sticky=\"w\")\n",
    "colourmap_combobox.set('viridis_r')\n",
    "\n",
    "tk.Label(root, text=\"Imagery:\").grid(row=6, column=0, sticky=\"e\")\n",
    "source1_entry = PlaceholderEntry(root, placeholder=\"Path to Planet Labs imagery\", width=40)\n",
    "source1_entry.grid(row=6, column=1, padx=5, pady=5, sticky=\"we\")\n",
    "tk.Button(root, text=\"Browse\", command=lambda: select_directory(source1_entry)).grid(row=6, column=2, padx=5, pady=5, sticky=\"w\")\n",
    "\n",
    "tk.Label(root, text=\"Shapefile:\").grid(row=7, column=0, sticky=\"e\")\n",
    "source2_entry = PlaceholderEntry(root, placeholder=\"Path to AOI shapefile\", width=40)\n",
    "source2_entry.grid(row=7, column=1, padx=5, pady=5, sticky=\"we\")\n",
    "tk.Button(root, text=\"Browse\", command=lambda: select_file(source2_entry)).grid(row=7, column=2, padx=5, pady=5, sticky=\"w\")\n",
    "\n",
    "tk.Label(root, text=\"Output:\").grid(row=8, column=0, sticky=\"e\")\n",
    "output1_entry = PlaceholderEntry(root, placeholder=\"Path to output\", width=40)\n",
    "output1_entry.grid(row=8, column=1, padx=5, pady=5, sticky=\"we\")\n",
    "tk.Button(root, text=\"Browse\", command=lambda: select_directory(output1_entry)).grid(row=8, column=2, padx=5, pady=5, sticky=\"w\")\n",
    "\n",
    "# Submit button creation\n",
    "submit_button = tk.Button(root, text=\"Submit\", command=submit_form)\n",
    "submit_button.grid(row=9, column=0, columnspan=3, pady=10)\n",
    "\n",
    "# Display Remote Sensing email address in GUI\n",
    "title_label = tk.Label(root, text=\"remotesensing@dlgwv.qld.gov.au\", font=(\"Arial\", 10), fg=\"#ffffff\", bg=main_bg_colour)\n",
    "title_label.grid(row=10, column=0, sticky=\"w\")\n",
    "\n",
    "# Display software version in GUI\n",
    "title_label = tk.Label(root, text=f\"Version {software_version}\", font=(\"Arial\", 10), fg=\"#ffffff\", bg=main_bg_colour)\n",
    "title_label.grid(row=10, column=2, sticky=\"se\")\n",
    "\n",
    "# Start the GUI event loop\n",
    "root.mainloop()\n",
    "\n",
    "# Only read analytical imagery\n",
    "image_files = glob.glob(os.path.join(base_dir, \"*Analytic*.tif\"))\n",
    "\n",
    "# Get current date and time\n",
    "current_datetime = datetime.datetime.now()\n",
    "\n",
    "# Format date and time into a string\n",
    "formatted_datetime = current_datetime.strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "# Define the name of the output subfolder\n",
    "subfolder_name = f\"{formatted_datetime}_Job_ID_{job_id}_Threshold_{ndwi_threshold}_Planet NDWI time series\"\n",
    "\n",
    "# Create the full path for the new subfolder\n",
    "output_path = os.path.join(gui_path, subfolder_name)\n",
    "\n",
    "# Create the subfolder\n",
    "os.makedirs(output_path)\n",
    "\n",
    "# Output Excel\n",
    "excel_filename = f\"{formatted_datetime}_Job_ID_{job_id}_Threshold_{ndwi_threshold}_Planet_NDWI_time_series.xlsx\"\n",
    "excel_file_path = os.path.join(output_path, excel_filename)\n",
    "\n",
    "# Specify the buffer distance (in units of the raster's CRS)\n",
    "buffer_distance = 50  # Adjust this value in metres as needed\n",
    "\n",
    "# Collect Python version information\n",
    "python_version = sys.version\n",
    "python_environment = sys.executable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14115.469092102829\n",
      "The projection name for the shapefile with EPSG code 32756 is, WGS 84 / UTM zone 56S.\n",
      "\n",
      "The projection name for the raster image with EPSG code 32756 is, WGS 84 / UTM zone 56S.\n",
      "\n",
      "Projections match.\n"
     ]
    }
   ],
   "source": [
    "# Open shapefile using geopandas\n",
    "shp = gpd.read_file(aoi)\n",
    "\n",
    "# Read the first tiff file:    \n",
    "raster_image = rasterio.open(image_files[0])\n",
    "tiff_band_1 = raster_image.read(1)\n",
    "\n",
    "# Check and get the projection name if shp.crs has an EPSG code\n",
    "shp_epsg_code = shp.crs.to_epsg()\n",
    "if shp_epsg_code:\n",
    "    shp_projection_name = get_projection_name(shp_epsg_code)\n",
    "    print(f\"The projection name for the shapefile with EPSG code {shp_epsg_code} is, {shp_projection_name}.\\n\")\n",
    "else:\n",
    "    print('The shapefile CRS does not have an EPSG code.')\n",
    "\n",
    "# Check and get the projection name if raster_image.crs has an EPSG code\n",
    "raster_image_epsg_code = raster_image.crs.to_epsg()\n",
    "if raster_image_epsg_code:\n",
    "    raster_image_projection_name = get_projection_name(raster_image_epsg_code)\n",
    "    print(f\"The projection name for the raster image with EPSG code {raster_image_epsg_code} is, {raster_image_projection_name}.\\n\")\n",
    "else:\n",
    "    print('The raster image CRS does not have an EPSG code.')\n",
    "\n",
    "# Check if projections match\n",
    "if shp.crs != raster_image.crs:\n",
    "    print('Projections do not match.')\n",
    "else:\n",
    "    print('Projections match.')\n",
    "    \n",
    "# Get raster extent\n",
    "raster_extent = [raster_image.bounds[0], raster_image.bounds[2], raster_image.bounds[1], raster_image.bounds[3]]\n",
    "\n",
    "# Create a new plot\n",
    "f, ax = plt.subplots()\n",
    "\n",
    "# Render image\n",
    "show(\n",
    "    tiff_band_1,\n",
    "    extent=raster_extent,\n",
    "    ax=ax,\n",
    ")\n",
    "\n",
    "# Add shapefile\n",
    "shp.plot(ax=ax, facecolor='w', edgecolor='k')\n",
    "ax.axis('off')\n",
    "ax.set_title('Projection Check')\n",
    "\n",
    "# Save image to output folder\n",
    "figure_filename = f\"{formatted_datetime}_Job_ID_{job_id}_PFI_{pfi}_Planet_NDWI_time_series.jpg\"\n",
    "figure_save_file_path = os.path.join(output_path, figure_filename)\n",
    "plt.savefig (figure_save_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop through images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting at 08/05/2025, 13:59:01\n",
      "\n",
      "Processing date: 19/04/2024\n",
      "Error: All classified raster values are nodata.\n",
      "\n",
      "Processing date: 19/04/2024\n",
      "Error: All classified raster values are nodata.\n",
      "\n",
      "Processing date: 19/04/2024\n",
      "\n",
      "Processing date: 21/04/2024\n",
      "\n",
      "Processing date: 22/04/2024\n",
      "\n",
      "Processing date: 22/04/2024\n",
      "\n",
      "Processing date: 23/04/2024\n",
      "\n",
      "Processing date: 23/04/2024\n",
      "\n",
      "Processing date: 23/04/2024\n",
      "Error: All classified raster values are nodata.\n",
      "\n",
      "Processing date: 24/04/2024\n",
      "\n",
      "Processing date: 25/04/2024\n",
      "\n",
      "Processing date: 26/04/2024\n",
      "\n",
      "Processing date: 27/04/2024\n",
      "\n",
      "Processing date: 27/04/2024\n",
      "\n",
      "Processing date: 28/04/2024\n",
      "\n",
      "Entire period processed, started at 08/05/2025, 13:59:01 and finished at 08/05/2025, 13:59:12.\n",
      "\n",
      "Total processing time: 0:00:11.461816.\n"
     ]
    }
   ],
   "source": [
    "# Initialise empty DataFrame\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# Record start\n",
    "start_time = datetime.datetime.now()\n",
    "print(\"Starting at \" + start_time.strftime(\"%d/%m/%Y, %H:%M:%S\"))\n",
    "\n",
    "# Time variables\n",
    "start_time_str = start_time.strftime(\"%d/%m/%Y, %H:%M:%S\")\n",
    "\n",
    "# Loop through image folder\n",
    "for image_file in image_files:\n",
    "    # Get base image name\n",
    "    image_name = os.path.basename(image_file)\n",
    "    \n",
    "    # UDM file name\n",
    "    udm_file = image_file.replace('AnalyticMS_SR', 'udm2').replace('AnalyticMS', 'udm2')\n",
    "    \n",
    "    # Convert the image file timestamp from UTC to AEST\n",
    "    aest_file_timestamp , aest_date = filename_utc_to_aest(image_name)    \n",
    "\n",
    "    # Prepend the converted timestamp to the original filename\n",
    "    output_image_name = f\"{aest_file_timestamp}_AEST_{image_name}\"\n",
    "    \n",
    "    # Get image date\n",
    "    image_date = image_name[:8]\n",
    "    image_date = dt.strptime(image_date, '%Y%m%d').strftime('%d/%m/%Y')\n",
    "\n",
    "    # Clip image and get the clipped image data and metadata in memory\n",
    "    clipped_data, clipped_meta = clip_raster_to_shapefile(image_file, aoi)\n",
    "    \n",
    "    # Assume nodata as None before getting the actual value from metadata\n",
    "    nodata = None\n",
    "    \n",
    "    # Clip AOI to buffer\n",
    "    shp = gpd.read_file(aoi)\n",
    "    \n",
    "    # Open the image with rasterio\n",
    "    with rasterio.open(image_file) as src:\n",
    "        # Buffer the AOI and then clip\n",
    "        buffered_aoi = shp.geometry.buffer(buffer_distance)\n",
    "        out_image, out_transform = rasterio.mask.mask(src, buffered_aoi, crop=True)\n",
    "        out_meta = src.meta.copy()\n",
    "        nodata = src.nodata\n",
    "        # If nodata is None, meaning it's not set in the metadata, decide on a nodata value for your outputs\n",
    "        if nodata is None:\n",
    "            nodata = -9999\n",
    "        out_meta.update({\n",
    "            \"driver\": \"GTiff\",\n",
    "            \"height\": out_image.shape[1],\n",
    "            \"width\": out_image.shape[2],\n",
    "            \"transform\": out_transform,\n",
    "            \"nodata\": nodata\n",
    "        })\n",
    "\n",
    "        # Define the output filename\n",
    "        buffered_output = os.path.join(output_path, f\"{output_image_name}_RGB_Buffered.tif\")\n",
    "        \n",
    "        # Save the buffered RGB clip to a new GeoTIFF file\n",
    "        with rasterio.open(buffered_output, \"w\", **out_meta) as dest:\n",
    "            dest.write(out_image)\n",
    "    \n",
    "    print(\"\\nProcessing date: \" + image_date)\n",
    "    \n",
    "    with MemoryFile() as memfile:\n",
    "        with memfile.open(**clipped_meta) as dataset:\n",
    "            # Retrieve the nodata value from the dataset\n",
    "            nodata = dataset.nodata\n",
    "\n",
    "            # Write the raster data to the dataset\n",
    "            dataset.write(clipped_data)\n",
    "            \n",
    "            # Calculate pixel size from from transform attribute\n",
    "            # abs to return only positive values that make sense to user\n",
    "            transform = dataset.transform\n",
    "            x_res = abs(transform.a) # Resolution in x direction\n",
    "            y_res = abs(transform.e) # Resolution in y direction\n",
    "            pixel_area_m2 = (x_res * y_res) \n",
    "\n",
    "            # Load green and NIR bands for NDWI calculation\n",
    "            bandgreen = dataset.read(2).astype('float32')\n",
    "            bandnir = dataset.read(4).astype('float32')\n",
    "            \n",
    "            if nodata is not None:\n",
    "                bandgreen[bandgreen == nodata] = np.nan\n",
    "                bandnir[bandnir == nodata] = np.nan\n",
    "\n",
    "            # Allow division by zero\n",
    "            np.seterr(divide='ignore', invalid='ignore')\n",
    "\n",
    "            # Calculate NDWI\n",
    "            ndwi = (bandgreen - bandnir) / (bandgreen + bandnir)\n",
    "\n",
    "            # Mask out the nan values in the NDWI result, if needed for further processing\n",
    "            ndwi_masked = np.ma.masked_invalid(ndwi)\n",
    "\n",
    "            # Ensures 'ndwi_threshold' is a number.\n",
    "            if ndwi_threshold is None:\n",
    "                raise ValueError(\"NDWI threshold is 'None', expected a float.\")\n",
    "\n",
    "            total_valid_area, below_threshold_area, percentage_below_threshold, above_threshold_area, percentage_above_threshold = measure_areas(ndwi, ndwi_threshold, pixel_area_m2)\n",
    "\n",
    "            # Perform classification from masked NDWI, ensuring nan values are ignored\n",
    "            classified = np.where(ndwi_masked >= ndwi_threshold, 1, 0).astype(np.uint8)\n",
    "            # print(f\"Classified Min: {classified.min()}, Max: {classified.max()}\")\n",
    "\n",
    "            # Create a colourmap (0: transparent, 1: blue)\n",
    "            colourmap = {0: (0, 0, 0, 0), 1: (0, 0, 254, 255)}\n",
    "            \n",
    "            # Define metadata for the new single-band GeoTIFF with classification\n",
    "            out_meta = dataset.meta.copy()\n",
    "            out_meta.update({\n",
    "                'driver': 'GTiff',\n",
    "                'dtype': 'uint8',\n",
    "                'count': 1,\n",
    "                'compress': 'lzw',\n",
    "                'nodata': 0,\n",
    "                'photometric': 'RGBA'\n",
    "            })\n",
    "        \n",
    "        # Before writing, check dimensions and potential issues\n",
    "        if classified.shape != (dataset.height, dataset.width):\n",
    "            print(\"Error: Classified raster dimensions do not match dataset dimensions.\")\n",
    "        elif classified.max() == nodata:\n",
    "            print(\"Error: All classified raster values are nodata.\")\n",
    "\n",
    "        # Define the output path\n",
    "        classified_output = os.path.join(output_path, f\"{output_image_name}_Threshold_{ndwi_threshold}_NDWI_Classified.tif\")  # Use os.path.join for cross-platform compatibility\n",
    "\n",
    "        # Set spatial characteristics of the output object to mirror the input\n",
    "        kwargs = dataset.meta\n",
    "        kwargs.update(\n",
    "        dtype=rasterio.float32,\n",
    "        count = 1\n",
    "        )\n",
    "\n",
    "        # Write out the classified raster with colourmap applied\n",
    "        with rasterio.open(classified_output, 'w', **out_meta) as dst:\n",
    "            dst.write(classified, 1)\n",
    "            dst.write_colormap(1, colourmap)\n",
    "\n",
    "            # Read UDM file for cloud, haze, and shadow\n",
    "            # Define metadata for a new single-band GeoTIFF\n",
    "            ndwi_meta = dataset.meta.copy()\n",
    "            ndwi_meta.update({\n",
    "                'dtype': 'uint8',\n",
    "                'count': 1,\n",
    "                'compress': 'lzw',\n",
    "                'nodata': 0  # Set the nodata value as required\n",
    "            })\n",
    "\n",
    "            # Clip the UDM file\n",
    "            with rasterio.open(udm_file) as src:\n",
    "                cloud_mask = src.read(6).astype(bool) # cloud is 6th band (index 5)\n",
    "                haze_mask = src.read(4).astype(bool) # haze is 4th band (index 3)\n",
    "                shadow_mask = src.read(3).astype(bool) # shadow is 3rd band (index 2)\n",
    "                extent = rasterio.plot.plotting_extent(src)\n",
    "\n",
    "            # Use rasterio's geometry mask to clip the UDM to the area of interest\n",
    "            with rasterio.open(udm_file) as src:\n",
    "                out_image, out_transform = rasterio.mask.mask(src, shp.geometry, crop=True)\n",
    "                out_meta = src.meta.copy()\n",
    "                out_meta.update({'driver': 'GTiff',\n",
    "                                'height': out_image.shape[1],\n",
    "                                'width': out_image.shape[2],\n",
    "                                'transform': out_transform})\n",
    "                \n",
    "                # Calculate the covered area for each mask\n",
    "                cloud_covered_area = calculate_covered_area(out_image[5], out_meta, shp)\n",
    "                haze_covered_area = calculate_covered_area(out_image[3], out_meta, shp)\n",
    "                shadow_covered_area = calculate_covered_area(out_image[2], out_meta, shp)\n",
    "\n",
    "                # Calculate cover percentages\n",
    "                cloud_covered_percentage = (cloud_covered_area / aoi_area) * 100\n",
    "                haze_covered_percentage = (haze_covered_area / aoi_area) * 100\n",
    "                shadow_covered_percentage = (shadow_covered_area / aoi_area) * 100\n",
    "\n",
    "    # Define kwargs here\n",
    "    kwargs = dataset.meta.copy()\n",
    "    kwargs.update(\n",
    "        dtype=rasterio.float32,\n",
    "        count=1)\n",
    "    \n",
    "    # Write out NDWI GeoTIFF image\n",
    "    ndwi_output = os.path.join(output_path, output_image_name + \"_NDWI.tif\")\n",
    "    with rasterio.open(ndwi_output, 'w', **kwargs) as dst:\n",
    "        dst.write_band(1, ndwi.astype(rasterio.float32))   \n",
    "\n",
    "    # Prepare the appropriate metadata\n",
    "    out_meta = dataset.meta.copy()\n",
    "    out_meta.update({\n",
    "        'driver': 'GTiff',\n",
    "        'height': classified.shape[0],  # Update to match classification array's height\n",
    "        'width': classified.shape[1],   # Update to match classification array's width\n",
    "        'transform': dataset.transform, # Update if you've altered the transform\n",
    "        'dtype': 'uint8',\n",
    "        'count': 1,  # Single-band raster\n",
    "        'compress': 'lzw',\n",
    "        'nodata': 255  # Nodata value\n",
    "    })\n",
    "    \n",
    "    # Use NumPy to mask out invalid pixels\n",
    "    ndwi_masked = np.ma.masked_invalid(ndwi)\n",
    "    \n",
    "    # Define the dimensions of the image\n",
    "    ndwi_shape = ndwi_masked.shape\n",
    "\n",
    "    # Create the plot area\n",
    "    fig, ax = plt.subplots(figsize=(12, 12))\n",
    "        \n",
    "    # Create a new figure with the same dimensions as ndwi_masked\n",
    "    fig = Figure(figsize=(ndwi_shape[1]/fig.dpi, ndwi_shape[0]/fig.dpi), dpi=fig.dpi)\n",
    "    canvas = FigureCanvasAgg(fig)\n",
    "    ax = fig.add_axes([0, 0, 1, 1])  # Add an axis that covers the entire figure\n",
    "\n",
    "    # Show the masked NDWI image without padding and without axes\n",
    "    ax.imshow(ndwi_masked, cmap=colour_map)\n",
    "    ax.axis('off')\n",
    "\n",
    "    # Add image_date text to the image at the top-left corner\n",
    "    timestamp_with_timezone = f\"{aest_file_timestamp} AEST\"  # Append 'AEST' to the timestamp\n",
    "    text_props = dict(boxstyle='round', facecolor='black', alpha=0.5)\n",
    "    ax.text(0.01, 0.99, timestamp_with_timezone, transform=ax.transAxes, fontsize=12, color='white', bbox=text_props, verticalalignment='top', horizontalalignment='left')\n",
    "\n",
    "    # Save the figure to a file with the given path and name\n",
    "    output_file_path = f\"{output_path}\\\\{output_image_name}_NDWI_Colour.png\"\n",
    "    fig.savefig(output_file_path, dpi=fig.dpi, bbox_inches='tight', pad_inches=0, transparent=True)\n",
    "\n",
    "    # We no longer need the figure after saving it, free the memory\n",
    "    plt.close(fig)\n",
    "    \n",
    "    # Gather statistics\n",
    "    bandgreen_min = np.nanmin(bandgreen)\n",
    "    bandgreen_max = np.nanmax(bandgreen)\n",
    "    bandgreen_mean = np.nanmean(bandgreen)\n",
    "           \n",
    "    bandnir_min = np.nanmin(bandnir)\n",
    "    bandnir_max = np.nanmax(bandnir)\n",
    "    bandnir_mean = np.nanmean(bandnir)\n",
    "               \n",
    "    ndwi_min = np.nanmin(ndwi)\n",
    "    ndwi_max = np.nanmax(ndwi)\n",
    "    ndwi_mean = np.nanmean(ndwi)\n",
    "\n",
    "    # Append results to DataFrame\n",
    "    new_row = pd.DataFrame({\n",
    "        \"Image Name\": [output_image_name + \"_NDWI.tif\"],\n",
    "        \"Image Date AEST\": [aest_date],\n",
    "        \"Total Area (sqm)\": [aoi_area],\n",
    "        \"Total Area (ha)\": [aoi_area/10000],\n",
    "        \"NDWI Area (sqm)\": [above_threshold_area],\n",
    "        \"NDWI Area (ha)\": [above_threshold_area/10000],\n",
    "        \"NDWI %\": [percentage_above_threshold],\n",
    "        \"Cloud Coverage (sqm)\": [cloud_covered_area],\n",
    "        \"Cloud %\": [cloud_covered_percentage],\n",
    "        \"Haze (sqm)\": [haze_covered_area],\n",
    "        \"Haze %\": [haze_covered_percentage],\n",
    "        \"Shadow (sqm)\": [shadow_covered_area],\n",
    "        \"Shadow %\": [shadow_covered_percentage],\n",
    "        \"NDWI Min\": [ndwi_min],\n",
    "        \"NDWI Max\": [ndwi_max],\n",
    "        \"NDWI Mean\": [ndwi_mean],\n",
    "        \"Green Band Min\": [bandgreen_min],\n",
    "        \"Green Band Max\": [bandgreen_max],\n",
    "        \"Green Band Mean\": [bandgreen_mean],\n",
    "        \"NIR Band Min\": [bandnir_min],\n",
    "        \"NIR Band Max\": [bandnir_max],\n",
    "        \"NIR Band Mean\": [bandnir_mean],\n",
    "    })\n",
    "    df = pd.concat([df, new_row], ignore_index=False)\n",
    "\n",
    "# Record end\n",
    "end_time = datetime.datetime.now()\n",
    "end_time_str = end_time.strftime(\"%d/%m/%Y, %H:%M:%S\")\n",
    "\n",
    "# Calculate processing time\n",
    "processing_time = end_time - start_time\n",
    "processing_time_str = str(processing_time)\n",
    "\n",
    "print(\"\\nEntire period processed, started at \" + start_time_str + \" and finished at \" + end_time_str + \".\\n\")\n",
    "print(\"Total processing time: \" + processing_time_str + \".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write metadata outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excel spreadsheet containing job information is here:\n",
      "\n",
      "Excel file path: C:/Local Output\\20250508_135900_Job_ID_251995_Threshold_0.0_Planet NDWI time series\\20250508_135900_Job_ID_251995_Threshold_0.0_Planet_NDWI_time_series.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Create a DataFrame with process metadata\n",
    "metadata_df = pd.DataFrame({\n",
    "    \"Variable Name\": [\"Job ID\",\n",
    "                      \"PFI\",\n",
    "                      \"Analyst\",\n",
    "                      \"NDWI Threshold\",\n",
    "                      \"Matplotlib Colourmap\",\n",
    "                      \"Start Date and Time\",\n",
    "                      \"End Date and Time\",\n",
    "                      \"Total Time HH:MM:SS.ss\",\n",
    "                      \"Shapefile EPSG Code\",\n",
    "                      \"Shapefile Projection Name\",\n",
    "                      \"Raster EPSG Code\",\n",
    "                      \"Raster Projection Name\",\n",
    "                      \"X Pixel Resolution (m)\",\n",
    "                      \"Y Pixel Resolution (m)\",\n",
    "                      \"Pixel Area (sqm)\",\n",
    "                      \"Source Imagery\",\n",
    "                      \"Source Shapefile\",\n",
    "                      \"Output Folder\",\n",
    "                      \"Software Version\",\n",
    "                      \"Python Version\",\n",
    "                      \"Python Environment\"],\n",
    "    \"Value\": [job_id,\n",
    "                pfi,\n",
    "                analyst,\n",
    "                ndwi_threshold,\n",
    "                colour_map,\n",
    "                start_time_str,\n",
    "                end_time_str,\n",
    "                processing_time_str,\n",
    "                shp_epsg_code,\n",
    "                shp_projection_name,\n",
    "                raster_image_epsg_code,\n",
    "                raster_image_projection_name,\n",
    "                x_res,\n",
    "                y_res,\n",
    "                pixel_area_m2,\n",
    "                base_dir,\n",
    "                aoi,\n",
    "                output_path,\n",
    "                software_version,\n",
    "                python_version,\n",
    "                python_environment]\n",
    "})\n",
    "\n",
    "# Create a dictionary to store the module names and versions\n",
    "module_versions = {}\n",
    "\n",
    "# Iterate over the modules dictionary and get the module name and version\n",
    "for module_name, module in modules.items():\n",
    "    try:\n",
    "        if module_name == 'Python':\n",
    "            version = sys.version.split()[0]\n",
    "        else:\n",
    "            version = module.__version__\n",
    "    except AttributeError:\n",
    "        version = 'Same as Python version'\n",
    "    module_versions[module_name] = version\n",
    "\n",
    "# Create a pandas DataFrame from the dictionary\n",
    "modules_df = pd.DataFrame(list(module_versions.items()), columns=['Module', 'Version'])\n",
    "\n",
    "# ExcelWriter to create an Excel output, add NDWI Output, Job Metadata, and Python Modules tabs\n",
    "writer = pd.ExcelWriter(excel_file_path, engine=\"xlsxwriter\")\n",
    "workbook = writer.book\n",
    "\n",
    "# Add Job NDWI Output tab\n",
    "df.to_excel(writer, sheet_name=\"NDWI Output\", index=False)\n",
    "# NDWI Output worksheet\n",
    "ndwi_output_worksheet = writer.sheets['NDWI Output']\n",
    "ndwi_output_worksheet.autofit()\n",
    "\n",
    "# Add Job Metadata tab\n",
    "metadata_df.to_excel(writer, sheet_name='Job Metadata', index=False, header=False)\n",
    "# Job Metadata worksheet\n",
    "metadata_worksheet = writer.sheets['Job Metadata']\n",
    "left_align_format = workbook.add_format({'align': 'left'})\n",
    "metadata_worksheet.set_column('B:B', None, left_align_format)\n",
    "metadata_worksheet.autofit() \n",
    "\n",
    "# Add Python module versions\n",
    "modules_df.to_excel(writer, sheet_name='Python Modules', index=False, header=False)\n",
    "# Python Modules worksheet\n",
    "python_modules_worksheet = writer.sheets['Python Modules']\n",
    "python_modules_worksheet.autofit()\n",
    "\n",
    "# Close the Pandas ExcelWriter and save the Excel file\n",
    "writer.close()\n",
    "\n",
    "print('Excel spreadsheet containing job information is here:\\n')\n",
    "print('Excel file path:', excel_file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RemoteSensingPlanet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
